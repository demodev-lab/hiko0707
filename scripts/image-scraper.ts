import { chromium, Browser, Page } from 'playwright'
import { writeFileSync, mkdirSync, existsSync } from 'fs'
import { join } from 'path'
import { HotDeal } from '@/types/hotdeal'
import { mockHotDeals } from '@/lib/db/mock-data'

interface ScrapedImage {
  productTitle: string
  imageUrl: string
  localPath: string
  thumbnailUrl: string
}

class ImageScraper {
  private browser: Browser | null = null
  private page: Page | null = null
  private outputDir = join(process.cwd(), 'public', 'images', 'products')

  async init() {
    this.browser = await chromium.launch({ 
      headless: false, // ë””ë²„ê¹…ì„ ìœ„í•´ ë¸Œë¼ìš°ì € í‘œì‹œ
      args: ['--no-sandbox', '--disable-setuid-sandbox']
    })
    this.page = await this.browser.newPage()
    
    // User-Agent ì„¤ì •
    await this.page.setExtraHTTPHeaders({
      'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })
    
    // ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if (!existsSync(this.outputDir)) {
      mkdirSync(this.outputDir, { recursive: true })
    }
  }

  async searchProductImage(productTitle: string, brand?: string): Promise<string | null> {
    if (!this.page) throw new Error('Browser not initialized')

    try {
      // ê²€ìƒ‰ì–´ ìµœì í™”
      const searchQuery = this.optimizeSearchQuery(productTitle, brand)
      console.log(`ğŸ” Searching for: ${searchQuery}`)

      // êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰
      await this.page.goto(`https://www.google.com/imghp?hl=ko`)
      await this.page.waitForSelector('input[name="q"]')
      
      // ê²€ìƒ‰ì–´ ì…ë ¥
      await this.page.fill('input[name="q"]', searchQuery)
      await this.page.press('input[name="q"]', 'Enter')
      
      // ì´ë¯¸ì§€ íƒ­ìœ¼ë¡œ ì´ë™ (ì´ë¯¸ ì´ë¯¸ì§€ ê²€ìƒ‰ì´ë©´ ìŠ¤í‚µ)
      try {
        await this.page.waitForSelector('a[href*="tbm=isch"]', { timeout: 3000 })
        await this.page.click('a[href*="tbm=isch"]')
      } catch {
        // ì´ë¯¸ ì´ë¯¸ì§€ íƒ­ì¸ ê²½ìš°
      }

      // ì´ë¯¸ì§€ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
      await this.page.waitForSelector('div[data-ri="0"] img', { timeout: 10000 })
      
      // ì²« ë²ˆì§¸ ì´ë¯¸ì§€ í´ë¦­
      await this.page.click('div[data-ri="0"] img')
      await this.page.waitForTimeout(2000)

      // í° ì´ë¯¸ì§€ URL ì¶”ì¶œ
      const imageUrl = await this.page.evaluate(() => {
        // ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì…€ë ‰í„° ì‹œë„
        const selectors = [
          'img[src*="encrypted-tbn0.gstatic.com"]',
          'img[data-iid]',
          'div[data-ri="0"] img',
          'img[jsname]'
        ]
        
        for (const selector of selectors) {
          const img = document.querySelector(selector) as HTMLImageElement
          if (img && img.src && !img.src.includes('data:') && img.src.includes('http')) {
            return img.src
          }
        }
        return null
      })

      if (imageUrl) {
        console.log(`âœ… Found image: ${imageUrl}`)
        return imageUrl
      } else {
        console.log(`âŒ No suitable image found for: ${searchQuery}`)
        return null
      }

    } catch (error) {
      console.error(`Error searching for ${productTitle}:`, error)
      return null
    }
  }

  private optimizeSearchQuery(title: string, brand?: string): string {
    // ì œí’ˆëª…ì—ì„œ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
    let cleanTitle = title
      .replace(/\[.*?\]/g, '') // ëŒ€ê´„í˜¸ ì œê±°
      .replace(/\(.*?\)/g, '') // ì†Œê´„í˜¸ ì œê±°
      .replace(/íŠ¹ê°€|í• ì¸|ë¬´ë£Œë°°ì†¡|í•œì •|ì´ë²¤íŠ¸/g, '') // ë§ˆì¼€íŒ… ë‹¨ì–´ ì œê±°
      .replace(/\d+%\s*í• ì¸/g, '') // í• ì¸ìœ¨ ì œê±°
      .trim()

    // ë¸Œëœë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if (brand && !cleanTitle.includes(brand)) {
      cleanTitle = `${brand} ${cleanTitle}`
    }

    return cleanTitle
  }

  async downloadImage(imageUrl: string, fileName: string): Promise<string | null> {
    if (!this.page) throw new Error('Browser not initialized')

    try {
      console.log(`ğŸ“¥ Downloading: ${imageUrl}`)
      
      // ìƒˆ íƒ­ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
      const newPage = await this.browser!.newPage()
      const response = await newPage.goto(imageUrl)
      
      if (response && response.ok()) {
        const buffer = await response.body()
        const filePath = join(this.outputDir, fileName)
        writeFileSync(filePath, buffer)
        await newPage.close()
        
        console.log(`âœ… Downloaded: ${filePath}`)
        return `/images/products/${fileName}`
      }
      
      await newPage.close()
      return null
    } catch (error) {
      console.error(`Error downloading ${imageUrl}:`, error)
      return null
    }
  }

  async scrapeHotDealImages(deals: HotDeal[], maxItems: number = 10): Promise<ScrapedImage[]> {
    const results: ScrapedImage[] = []
    
    for (let i = 0; i < Math.min(deals.length, maxItems); i++) {
      const deal = deals[i]
      console.log(`\nğŸ“¦ Processing ${i + 1}/${maxItems}: ${deal.title}`)
      
      try {
        // ì´ë¯¸ì§€ ê²€ìƒ‰
        const imageUrl = await this.searchProductImage(deal.title, deal.seller)
        
        if (imageUrl) {
          // íŒŒì¼ëª… ìƒì„±
          const fileName = `${deal.category}_${i + 1}_${Date.now()}.jpg`
          
          // ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
          const localPath = await this.downloadImage(imageUrl, fileName)
          
          if (localPath) {
            results.push({
              productTitle: deal.title,
              imageUrl: imageUrl,
              localPath: localPath,
              thumbnailUrl: localPath
            })
          }
        }
        
        // ìš”ì²­ ê°„ê²© (êµ¬ê¸€ ì°¨ë‹¨ ë°©ì§€)
        await this.page!.waitForTimeout(3000 + Math.random() * 2000)
        
      } catch (error) {
        console.error(`Error processing ${deal.title}:`, error)
        continue
      }
    }
    
    return results
  }

  async updateHotDealsWithImages(scrapedImages: ScrapedImage[]): Promise<void> {
    // ìŠ¤í¬ë˜í•‘ëœ ì´ë¯¸ì§€ ì •ë³´ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    const imageMapping = scrapedImages.reduce((acc, img, index) => {
      acc[index] = img.localPath
      return acc
    }, {} as Record<number, string>)
    
    const mappingPath = join(process.cwd(), 'lib', 'db', 'image-mapping.json')
    writeFileSync(mappingPath, JSON.stringify(imageMapping, null, 2))
    
    console.log(`ğŸ’¾ Image mapping saved to: ${mappingPath}`)
    console.log('ğŸ“‹ Results:')
    scrapedImages.forEach((img, i) => {
      console.log(`  ${i + 1}. ${img.productTitle} â†’ ${img.localPath}`)
    })
  }

  async close() {
    if (this.browser) {
      await this.browser.close()
    }
  }
}

// ì‹¤í–‰ í•¨ìˆ˜
async function main() {
  const scraper = new ImageScraper()
  
  try {
    console.log('ğŸš€ Starting image scraping...')
    await scraper.init()
    
    // ì²˜ìŒ 10ê°œ í•«ë”œì— ëŒ€í•´ ì´ë¯¸ì§€ ìˆ˜ì§‘
    const results = await scraper.scrapeHotDealImages(mockHotDeals, 10)
    
    // ê²°ê³¼ ì €ì¥
    await scraper.updateHotDealsWithImages(results)
    
    console.log(`\nğŸ‰ Completed! Successfully scraped ${results.length} images.`)
    
  } catch (error) {
    console.error('âŒ Error:', error)
  } finally {
    await scraper.close()
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
if (require.main === module) {
  main()
}

export { ImageScraper }