import fs from 'fs';
import path from 'path';
import { HotDeal, HotDealSource } from '@/types/hotdeal';

interface CrawledData {
  metadata: {
    exportDate: string;
    totalDeals: number;
    source: string;
    version: string;
    exportedBy: string;
    crawledPages: number;
  };
  hotdeals: CrawledHotDeal[];
}

interface CrawledHotDeal {
  id: string;
  title: string;
  content: string;
  price: string;
  originalPrice: string | null;
  discount: string | null;
  storeName: string;
  category: string;
  thumbnailImage: string;
  originalImage: string;
  author: string;
  postDate: string;
  views: number;
  recommendCount: number;
  commentCount: number;
  url: string;
  isEnded: boolean;
  isFreeShipping: boolean;
  isPopular: boolean;
  source: string;
  sourcePostId: string;
  crawledPage: number;
  createdAt: string;
  updatedAt: string;
}

export function convertCrawledDataToHotDeals(crawledFilePath: string): HotDeal[] {
  const fileContent = fs.readFileSync(crawledFilePath, 'utf-8');
  const crawledData: CrawledData = JSON.parse(fileContent);
  
  return crawledData.hotdeals.map((deal, index) => {
    // ê°€ê²©ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
    const priceMatch = deal.price?.match(/[\d,]+/);
    const price = priceMatch ? parseInt(priceMatch[0].replace(/,/g, '')) : 0;
    
    const hotDeal: HotDeal = {
      id: `crawled_${deal.sourcePostId}_${Date.now()}_${index}`,
      title: deal.title,
      price: price,
      imageUrl: deal.originalImage || deal.thumbnailImage,
      originalUrl: deal.url,
      seller: deal.storeName,
      source: deal.source as HotDealSource,
      crawledAt: new Date(deal.postDate),
      userId: deal.author,
      communityCommentCount: deal.commentCount,
      communityRecommendCount: deal.recommendCount,
      ranking: undefined,
      shipping: {
        isFree: deal.isFreeShipping
      },
      productComment: deal.content,
      category: deal.category,
      status: deal.isEnded ? 'ended' : 'active',
      viewCount: deal.views,
      likeCount: 0,
      commentCount: 0,
      translationStatus: 'pending'
    };
    
    return hotDeal;
  });
}

// ì‹¤í–‰ í•¨ìˆ˜
export async function importCrawledData(crawledFilePath: string) {
  try {
    console.log(`ğŸ“¥ í¬ë¡¤ë§ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°: ${crawledFilePath}`);
    
    const hotDeals = convertCrawledDataToHotDeals(crawledFilePath);
    
    // ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ê¸°ì¡´ mock ë°ì´í„°ì— ì¶”ê°€)
    const { db } = await import('@/lib/db/database-service');
    
    for (const deal of hotDeals) {
      await db.hotdeals.create(deal);
    }
    
    console.log(`âœ… ${hotDeals.length}ê°œì˜ í•«ë”œì´ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™€ì¡ŒìŠµë‹ˆë‹¤.`);
    return hotDeals;
    
  } catch (error) {
    console.error('âŒ í¬ë¡¤ë§ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:', error);
    throw error;
  }
}

// CLI ì‹¤í–‰ìš©
if (require.main === module) {
  const filePath = process.argv[2];
  if (!filePath) {
    console.error('âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.');
    console.log('ì‚¬ìš©ë²•: tsx scripts/import-crawled-data.ts <íŒŒì¼ê²½ë¡œ>');
    process.exit(1);
  }
  
  importCrawledData(filePath)
    .then(() => {
      console.log('ğŸ‰ í¬ë¡¤ë§ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ');
      process.exit(0);
    })
    .catch((error) => {
      console.error('ğŸ’¥ ì‹¤í–‰ ì‹¤íŒ¨:', error);
      process.exit(1);
    });
}